# Generate fake data for Divergence Point Analysis

# Imports that produce dependencies
#import numpy as np     # requires `pip install numpy`
import pandas as pd    # requires `pip install pandas`

# Python native imports
import os
import math
import argparse
import random

PRETRIAL_BUFFER = 1000
all_fixation_lengths = []                               # for stats

MAX_PROB_POINT_X = 1000                                 # see get_event_probs()
MAX_PROB_POINT_C = MAX_PROB_POINT_X / math.log2(100)

def parse_command_line():
    description = ''
    argparser = argparse.ArgumentParser(description=description)
    argparser.add_argument('--n_subjs', metavar='n_subjs',
                           type=int,
                           default=50,
                           help='Number of participants to be generated')

    argparser.add_argument('--n_trials', metavar='n_trials',
                           type=int,
                           default=12,
                           help='Number of trials to be generated by participant '
                                'by condition (e.g., if it is 2, then a given '
                                'participant will have 2 trials per condition).')

    argparser.add_argument('--trial_len', metavar='trial_len',
                           type=int,
                           default=1000,
                           help='Length of the trial in miliseconds.')

    argparser.add_argument('--dpoint', metavar='dpoint',
                           type=int,
                           default=300,
                           help='The divergence point for condition 0 (in ms).')

    argparser.add_argument('--n_conds', metavar='n_conds',
                           type=int,
                           default=2,
                           help='How many conditions we have.')

    argparser.add_argument('--cond_effect', metavar='cond_effect',
                           type=int,
                           default=150,
                           help='The main effect of condition. For simplicity, each '
                                'new condition has its divergence point delayed by '
                                '`cond_effect`. (e.g., if it is 100, then the second '
                                'condition will diverge 100ms after the first, '
                                'the third condition will diverge 100ms after the '
                                'second, and so on.)')


    # Random noise per trial. This is uncontrollable! Every participant varies
    # every trial just a little bit, simply because they're human
    argparser.add_argument('--rand_dp_noise_sd',
                           metavar='rand_dp_noise_sd',
                           type=float,
                           default=10,
                           help='Every trial has a divergence point that is just '
                                'a bit randomly different. This defines the SD '
                                '(in ms) of this variability.')

    argparser.add_argument('--rand_prob_noise_sd',
                           metavar='rand_prob_noise_sd',
                           type=float,
                           default=0.5,
                           help='Every trial is just slightly (and randomly) biased '
                                'towards one or the other image. This defines the SD '
                                '(in probability) of this variability.')

    argparser.add_argument('--rand_dspeed_noise_sd',
                           metavar='rand_dspeed_noise_sd',
                           type=float,
                           default=5,
                           help='Every trial is just slightly (and randomly) varied '
                                'on the "speed" with which the divergence happens. '
                                'That is, how quickly the probability of fixating on '
                                'the target increases, after the divergence point '
                                'has passed. (This is not in a clear "unit", like '
                                '"prob/ms", or anything. The value you choose here '
                                'will just influence the sigmoid '
                                'function.)')

    # Per trial per participant variables.
    # Over the random noise, some participants may have more variability, and some
    # may have less. This depends on the participant.

    argparser.add_argument('--subj_per_trial_dpoint_var_sd',
                           metavar='subj_per_trial_dpoint_var_sd',
                           type=float,
                           default=10,
                           help='The divergence point variability SD, per trial, of '
                                'participants. (some participants vary more, some vary '
                                'less.)')

    argparser.add_argument('--subj_per_trial_bias_var_sd',
                           metavar='subj_per_trial_bias_var_sd',
                           type=float,
                           default=0.5,
                           help='The variability SD, per trial, of the participant '
                                'bias towards one or the other image. (some participants '
                                'vary more, some vary less.)')

    argparser.add_argument('--subj_per_trial_dspeed_var_sd',
                           metavar='subj_per_trial_dspeed_var_sd',
                           type=float,
                           default=5,
                           help='The variability SD, per trial, of the participant '
                                'divergence "speed" towards one or the other image. '
                                '(This is not in a clear "unit", like '
                                '"prob/ms", or anything. The value you choose here '
                                'will just influence the sigmoid '
                                'function.)')


    # Per participant variables. This is set once for each participant

    # Random effects
    argparser.add_argument('--subj_dpoint_rand_intercept_sd',
                           metavar='subjs_dpoint_rand_intercept_sd',
                           type=float,
                           default=50,
                           help="The variability (in ms) of the random intercept of "
                                "participants' divergence point.")

    argparser.add_argument('--subj_dpoint_rand_slope_sd',
                           metavar='subj_dpoint_rand_slope_sd',
                           default=50,
                           type=float,
                           help="The variability (in ms) of the random slope of "
                                "participants' divergence point. The random "
                                "slope will be a slight change (per participant) "
                                "of the effect of the condition.")

    argparser.add_argument('--subj_bias_var_sd',
                           metavar='subj_bias_var_sd',
                           type=float,
                           default=0.5,
                           help='The variability of a per-participant bias '
                                '(in probability) of looking towards one or the '
                                'other image.')

    argparser.add_argument('--subj_dspeed_bias_var_sd',
                           metavar='subj_dspeed_bias_var_sd',
                           type=float,
                           default=5,
                           help='The variability of a per-participant bias '
                                'of diverging either faster or slower once past '
                                'the divergence point. '
                                '(This is not in a clear "unit", like '
                                '"prob/ms", or anything. The value you choose here '
                                'will just influence the sigmoid '
                                'function.)')

    # I will assume participants don't diverge different (don't have different
    # `dspeed`) in the different conditions.

    # For now, I'm assuming all items are equal.


    argparser.add_argument('--out_file', metavar='out_file',
                           type=str, default='fake_data.csv',
                           help='File to be produced with the data')

    argparser.add_argument('--dump_per_trial_fixation_stats',
                           metavar='dump_per_trial_fixation_stats',
                           type=bool, default=True,
                           help='If set, produces a file with statistics of the '
                                'fixations of each trial. Each row will contain stats '
                                'of a given trial. The last row will contain an '
                                'average of all previous rows. The file will be '
                                'called `per_trial_fixation_stats.csv`.')

    argparser.add_argument('--dump_overall_fixation_stats',
                           metavar='dump_overall_fixation_stats',
                           type=bool, default=True,
                           help='(Requires library plotnine) If set, produces a folder '
                                'with statistics about the length of the fixations, '
                                'regardless of which trial they come from. The folder '
                                'is called `fixation_stats`')

    # argparser.add_argument('--parser', metavar='parser', type=str,
    #                     default='spacy',
    #                     help='Which parser to use ("nltk" or "spacy")')

    return argparser.parse_args()

def sigmoid(x, slow_factor=50, rand_effect=0.):
    # This is:
    #               x
    #              e
    # sigmoid(x) = ------
    #                   x
    #              1 + e
    #
    # `slow_factor` is just supposed to make it approach 1 slower.
    return ((math.e ** (x/(slow_factor+rand_effect))) /
            (1 + math.e ** (x/(slow_factor+rand_effect))))

def get_look_probs(trial_len,
                   pretrial_buffer,
                   cond,
                   subj_per_trial_dp_var_sd,
                   subj_per_trial_bias_var_sd,
                   subj_per_trial_dspeed_var_sd,
                   subj_bias_toward_obj,
                   subj_dspeed_bias,
                   subj_dpoint_random_intercept,
                   subj_dpoint_random_slope,
                   args):
    condition_fixed_effect = cond * (args.cond_effect + subj_dpoint_random_slope)

    random_dp_noise = int(random.gauss(mu=0, sigma=args.rand_dp_noise_sd))
    random_prob_noise = random.gauss(mu=0, sigma=args.rand_prob_noise_sd)
    random_dspeed_noise = random.gauss(mu=0, sigma=args.rand_dspeed_noise_sd)

    subj_per_trial_dp_var = int(random.gauss(mu=0, sigma=subj_per_trial_dp_var_sd))
    subj_per_trial_bias_var = int(random.gauss(mu=0, sigma=subj_per_trial_bias_var_sd))
    subj_per_trial_dspeed_var = random.gauss(mu=0, sigma=subj_per_trial_dspeed_var_sd)

    divergence_moment = (
            pretrial_buffer +
            args.dpoint +
            random_dp_noise +
            condition_fixed_effect +
            subj_dpoint_random_intercept +
            subj_per_trial_dp_var
    )
    #print(condition_fixed_effect, random_dp_noise, random_prob_noise , subj_dpoint_random_intercept,
    #      subj_per_trial_dp_var_sd,
    #      subj_per_trial_dp_var, divergence_moment)

    return ([0.5 + random_prob_noise + subj_per_trial_bias_var + subj_bias_toward_obj
             for i in range(divergence_moment)]
            +
            [sigmoid(i, rand_effect=random_dspeed_noise + subj_per_trial_dspeed_var + subj_dspeed_bias) +
             random_prob_noise + subj_per_trial_bias_var + subj_bias_toward_obj
             for i in range(trial_len-divergence_moment)])


def get_event_probs():
    # Ok... for the "exponential decay" probability of there being an event,
    # we'll use the (seemingly bizarre) function:
    #
    #   x / c
    # 2
    # --------
    #   100
    #
    # where `c` is a constant value chosen to make the exponential "slower".
    #
    # The choice of this function (and of c) has the following reasoning:
    # 1) It is an exponential, so it increases very (!) slowly in the beginning
    # 2) It has the convenience of passing through a convenient point of choice.
    #    The commented lines below show where this point might be (I started out
    #    with (300,1), but noticed that it still caused the fixations to be too
    #    short. So I tried out other points).
    #
    # The value of c is calculated as follows. Say I wanted it to pass by the
    # point (300,1). In that case, since my function looks like y = (2**(x/c))/100
    # then, if I substitute x=300 and y=1, I get:
    #
    # 1 = (2**(300/c))/100          # pass the 100 to the other side
    # 100 = 2**(300/c)              # apply log2 to both sides (gets rid of the 2**)
    # log2(100) = 300/c             # pass c to the other side
    # c log2(100) = 300             # pass log2(100) to the other side
    # c = 300/log2(100) = 45.15449934959718
    #
    # Basically, I'm hoping to force most fixations to last somewhere in the
    # range 180ms~250ms, because this is the typical length of a real fixation.
    #
    #return [(2 ** (i/45.15449934959718) / 100) for i in range(301)]   # passes (300,1)
    #return [(2 ** (i/60.205999132796244) / 100) for i in range(401)]  # passes (400,1)
    #return [(2 ** (i/75.2574989159953) / 100) for i in range(501)]    # passes (500,1)
    #return [(2 ** (i/105.36049848239342) / 100) for i in range(701)]  # passes (700,1)
    #
    # Ok... it turns out that just the exponential is not enough. I need
    # a stronger drug. Let's try the exponential of exponentials. The calculation
    # is the same, only with more logs/exponentials.
    return [(2 ** (i/MAX_PROB_POINT_C) / 100) for i in range(MAX_PROB_POINT_X+1)]
    #return [(2**(2**(2**(2**(i/MAX_PROB_POINT_C)))) / 100) for i in range(MAX_PROB_POINT_X+1)]



def get_events(trial_len):
    # I am using the word "event" here to denote (basically) the fixations.
    # The plan is to have an event happen every ~200ms (a typical fixation has
    # between 180ms and 250ms), and for it to be super rare for fixations to
    # happen immediately one after another.
    events = []

    probs_vector = []
    fixation_lengths = []

    while (len(events) < trial_len):
        # Probs behave as if there were always an event in the first millisecond
        # (but this won't matter once we eventually discard the first milliseconds --
        # see PRETRIAL_BUFFER)
        probs = get_event_probs()
        fix_len = 0                                     # for stats

        for p in probs:
            curr_event = random.random() < p
            events.append(curr_event)

            probs_vector.append(p)                      # for stats
            fix_len += 1                                # for stats

            if curr_event:
                # We got an event, time to reset
                break
            if len(events) >= trial_len:
                # Without this, we may get stuck in the for loop for too long
                break

        fixation_lengths.append(fix_len)                # for stats

    all_fixation_lengths.append(fixation_lengths)
    return events

def create_dataframe(looks, subj_id, trial_id, cond):
    data = []
    for idx,i in enumerate(looks):
        # For now, I'll assume there's always only a Target and a Distractor
        data.append((idx, 'Target', int(i)))
        data.append((idx, 'Distractor', int(not i)))

    milliseconds, objs, is_looking = zip(*data)

    trial_data = pd.DataFrame(data={
        'participant': subj_id,
        'condition': cond,
        'trial': trial_id,
        'time': milliseconds,
        'object': objs,
        'is_looking': is_looking
    })
    return trial_data


def generate_trial_data(subj_id,
                        trial_id,
                        cond,
                        subj_per_trial_dp_var_sd,
                        subj_per_trial_bias_var_sd,
                        subj_per_trial_dspeed_var_sd,
                        subj_bias_toward_obj,
                        subj_dspeed_bias,
                        subj_dpoint_random_intercept,
                        subj_dpoint_random_slope,
                        args):
    prob = get_look_probs(
        args.trial_len + PRETRIAL_BUFFER, PRETRIAL_BUFFER,
        cond,
        subj_per_trial_dp_var_sd,
        subj_per_trial_bias_var_sd,
        subj_per_trial_dspeed_var_sd,
        subj_bias_toward_obj,
        subj_dspeed_bias,
        subj_dpoint_random_intercept,
        subj_dpoint_random_slope,
        args
    )

    # The additional time (PRETRIAL_BUFFER) is so that we can treat better
    # the trial beginning
    looks = []
    events = get_events(args.trial_len + PRETRIAL_BUFFER)
    curr_looking_at = random.random() < prob[0]
    for ms, e in enumerate(events):
        if e:
            curr_looking_at = random.random() < prob[ms]
        looks.append(curr_looking_at)

    trial_data = create_dataframe(looks[PRETRIAL_BUFFER:], subj_id, trial_id, cond)

    return trial_data

def generate_subj_data(subj_id, args):
    n_conditions = args.n_conds

    # These influence variations that occur every trial
    subj_per_trial_dp_var_sd = random.gauss(mu=0, sigma=args.subj_per_trial_dpoint_var_sd)
    subj_per_trial_bias_var_sd = random.gauss(mu=0, sigma=args.subj_per_trial_bias_var_sd)
    subj_per_trial_dspeed_var_sd = random.gauss(mu=0, sigma=args.subj_per_trial_dspeed_var_sd)

    # These are fixed for each subject
    subj_bias_toward_obj = random.gauss(mu=0, sigma=args.subj_bias_var_sd)
    subj_dspeed_bias = random.gauss(mu=0, sigma=args.subj_dspeed_bias_var_sd)

    # This is the effect of condition on each participant
    # TODO: Maybe this should inside the for loop, recalculated every condition.
    #       It won't matter now because there're only 2 conditions.
    subj_dpoint_random_intercept = int(random.gauss(mu=0, sigma=args.subj_dpoint_rand_intercept_sd))
    subj_dpoint_random_slope = int(random.gauss(mu=0, sigma=args.subj_dpoint_rand_slope_sd))

    # `subj_trials` is a list of data frames
    subj_trials = []
    for cond in range(n_conditions):

        for trial in range(args.n_trials):
            trial_id = "T" + str(trial)

            subj_trials.append(
                generate_trial_data(
                    subj_id,
                    trial_id,
                    cond,
                    subj_per_trial_dp_var_sd,
                    subj_per_trial_bias_var_sd,
                    subj_per_trial_dspeed_var_sd,
                    subj_bias_toward_obj,
                    subj_dspeed_bias,
                    subj_dpoint_random_intercept,
                    subj_dpoint_random_slope,
                    args)
            )
    return subj_trials


def generate_data(args):
    # `all_data` is a list of data frames
    all_data = []
    for subj in range(args.n_subjs):
        subj_id = "P" + str(subj)
        # Define other variables
        subj_trials = generate_subj_data(subj_id, args)
        all_data.extend(subj_trials)

    return pd.concat(all_data, axis=0)


def per_trial_fixation_stats():
    maxes = []
    mins = []
    means = []
    medians = []
    means_without_last = []
    medians_without_last = []

    for i in all_fixation_lengths:
        maxes.append(max(i))
        mins.append(min(i))
        means.append(s.mean(i))
        medians.append(s.median(i))
        means_without_last.append(s.mean(i[:-1]))
        medians_without_last.append(s.median(i[:-1]))

    # Now, let's get the average of them all into the last line
    maxes.append(s.mean(maxes))
    mins.append(s.mean(mins))
    means.append(s.mean(means))
    medians.append(s.mean(medians))
    means_without_last.append(s.mean(means_without_last))
    medians_without_last.append(s.mean(medians_without_last))

    df = pd.DataFrame(data={
        "Max": maxes,
        "Min": mins,
        "Mean": means,
        "Median": medians,
        "Mean_nolast": means_without_last,
        "Median_nolast": medians_without_last
    })
    return df


def overall_fixation_stats(out_folder):
    # I know this is unreadable. Look here: https://stackoverflow.com/a/952952
    all_fixations = [i for j in all_fixation_lengths for i in j]

    # First, let's assume this is a normal distribution. What can we calculate?
    max_f = max(all_fixations)
    min_f = min(all_fixations)
    mean_f = s.mean(all_fixations)
    median_f = s.median(all_fixations)
    sd_f = s.stdev(all_fixations)

    # Now I want to plot these. I want to see the distribution.
    df = pd.DataFrame({
        'x': all_fixations
    })
    p = ggplot(df, aes(x='x')) + geom_histogram(fill='lightblue', color='black')

    # Dump stuff
    if not os.path.exists(out_folder):
        os.makedirs(out_folder)

    with open(os.path.join(out_folder, 'overall_fixation_stats.txt'), 'w') as f:
        f.write("max, min, mean, median, sd\n")
        f.write("{}, {}, {}, {}, {}".format(max_f, min_f, mean_f, median_f, sd_f))
    p.save(os.path.join(out_folder, 'histogram_fixation.svg'))




if __name__ == '__main__':
    # Tests the functionalities of this file
    print("Parsing command line...")
    args = parse_command_line()
    print("Generating data...")
    out_df = generate_data(args)
    print("Dumping into output file...")
    out_df.to_csv(args.out_file)

    if args.dump_per_trial_fixation_stats:
        import statistics as s
        print("Calculating per trial fixation stats...")
        stats = per_trial_fixation_stats()
        print("Dumping per trial fixation stats...")
        stats.to_csv('per_trial_fixation_stats.csv')
        print(stats)

    if args.dump_overall_fixation_stats:
        import statistics as s
        from plotnine import *
        print("Calculating overall fixation stats...")
        stats = overall_fixation_stats('fixation_stats')
        print("Dumping per trial fixation stats...")

    print("Done")

